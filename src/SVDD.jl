mutable struct SVDD{T, N, K <: XKernel}
    RÂ²     :: T
    Wáµ€KW   :: T
    ğŸW     :: Matrix{T}
    svecs  :: Matrix{T}
    kernel :: K
    function SVDD{T,N}(RÂ²::Real, Wáµ€KW::Real, W::Matrix, svecs::Matrix, kernel::K) where {T, N, K <: XKernel}
        @assert N==1 || N==2 begin
            "only support type SVDD{T,1} or SVDD{T,2}, got SVDD{T,$N}"
        end
        new{T,N,K}(RÂ², Wáµ€KW, 2W, svecs, kernel)
    end
end


@inline nsvs(S::SVDD) = length(S.ğŸW)


function Base.show(io::IO, ::MIME"text/plain", svdd::SVDD{T,N,K}) where {T, N, K <: XKernel}
    C = nsvs(svdd)
    print(io, "SVDD{$T,$N,$K} with $C support vectors")
end


"""
    SVDD(kernel <: XKernel, x::Matrix{Real}, C::Real, Ïµ::Real=1e-3)

`x` is the normal data,  `C` is the penalty coefficient (the bigger the less error allowed), 
lagrange multipliers below the threshold `Ïµ` will be discarded.
"""
function SVDD(kernel::KERNEL, x::Matrix{T}, C::Real, Ïµ::Real=1e-3) where {T <: Real, KERNEL <: XKernel}
    C = T(C)
    N = size(x, 2)
    if C < 1 / N
        BUG = """
        due to the constraints:
            âˆ‘áµ¢Î±áµ¢= 1
            0 â‰¤ Î±áµ¢ â‰¤ C
            i = 1 ... N
        the penalty coefficient C s.t. C â‰¥ 1 / N, but got $C â‰¥ 1 / $N .
        Now C would be set as 1 to make sure the code runs smoothly.
        """
        @warn BUG
        C = one(T)
    end

    a = ones(T, N, 1) ./ N
    K = kmat(kernel, x, x, obsdim=2)
    Ki = reshape(diag(K), 1, N);

    # ä¼˜åŒ–æ¨¡å‹å‚æ•°
    model = JuMP.Model(optimizer_with_attributes(COSMO.Optimizer, "verbose" => true));
    @variable(model, a[1:N]);
    @objective(model, Min, sum(a' * K * a) - sum(Ki * a));
    @constraint(model, sum(a) == 1);
    @constraint(model, 0 .â‰¤ a .â‰¤ C);
    status = JuMP.optimize!(model);
    
    Î± = value.(a)
    Ïµ = T(Ïµ)
    ğŸ = T(2)
    # æå–æ”¯æ’‘å‘é‡
    idS = Int[]  # =R s.t. 0 < Î±áµ¢ < C
    i0C = Int[]  # â‰¥R s.t. 0 < Î±áµ¢ â‰¤ C
    for (i, Î±áµ¢) âˆˆ enumerate(Î±)
        if Ïµ < Î±áµ¢
            if Î±áµ¢ < C - Ïµ
                push!(idS, i)
            end
            push!(i0C, i)
        end
    end

    j = 0
    if length(idS) > 0
        j = idS[1]
    else
        @error "there is no support vector"
    end

    Î±áµ¢ = Î±[i0C,:]
    Xi = x[:,i0C]
    Xs = x[:,j:j]

    Kss = kmat(kernel, Xs, Xs, obsdim=2)
    Kis = kmat(kernel, Xi, Xs, obsdim=2)
    Kij = kmat(kernel, Xi, Xi, obsdim=2)
    Î±áµ€KÎ± = Î±áµ¢' * Kij * Î±áµ¢
    RÂ²   = Kss - ğŸ * Î±áµ¢' * Kis + Î±áµ€KÎ±

    return SVDD{T,1}(first(RÂ²), first(Î±áµ€KÎ±), Î±áµ¢, Xi, kernel)
end


function _SVDD(kernel::KERNEL, x::Matrix{T}, y::Vector{Int}, C::T, Ïµ::T=1e-3) where {T <: Real, KERNEL <: XKernel}
    N = size(x,2)      # number of features
    M = length(y)      # number of labels

    y = reshape(y, N, 1)
    a = ones(T, N, 1) ./ N
    K = T.(y * y') .* kmat(kernel, x, x, obsdim=2)
    Ki = reshape(diag(K), 1, N)

    # ä¼˜åŒ–æ¨¡å‹å‚æ•°
    model = JuMP.Model(optimizer_with_attributes(COSMO.Optimizer, "verbose" => true));
    @variable(model, a[1:N])
    @objective(model, Min, sum(a' * K * a) - sum(Ki * a));
    @constraint(model, sum(y .* a) == 1)
    @constraint(model, 0 .â‰¤ a .â‰¤ C)
    status = JuMP.optimize!(model)
    
    Î± = value.(a)
    ğŸ = T(2)
    # æå–æ”¯æ’‘å‘é‡
    idS = Int[]  # supports s.t. 0 < Î±áµ¢ < C
    i0C = Int[]  # outers s.t.   0 < Î±áµ¢ â‰¤ C
    for (i, Î±áµ¢) âˆˆ enumerate(Î±)
        if Ïµ < Î±áµ¢
            if Î±áµ¢ < C - Ïµ
                push!(idS, i)
            end
            push!(i0C, i)
        end
    end
    Î±áµ¢ = Î±[i0C,:]
    yáµ¢ = y[i0C,:]
    Wáµ¢ = yáµ¢ .* Î±áµ¢
    
    # chose one support vec
    j = 0
    if length(idS) > 0
        j = idS[1]
    else
        @error "there is no support vector"
    end

    Ys = y[j,:]
    Xi = x[:,i0C]
    Xs = x[:,j:j]

    Kss = kmat(kernel, Xs, Xs, obsdim=2)
    Kis = kmat(kernel, Xi, Xs, obsdim=2)
    Kij = kmat(kernel, Xi, Xi, obsdim=2)
    Wáµ€KW = Wáµ¢' * Kij * Wáµ¢
    RÂ²   = Kss - ğŸ * Wáµ¢' * Kis + Wáµ€KW

    return SVDD{T,2}(first(RÂ²), first(Wáµ€KW), Wáµ¢, Xi, kernel)
end


"""
    SVDD(kernel <: XKernel, xpos::Matrix{T}, xneg::Matrix{Real}, C::Real, Ïµ::Real=1e-3)

`xpos` is the normal data and `xneg` is the abnormal data,  `C` is the penalty coefficient (the bigger the less error allowed), 
lagrange multipliers below the threshold `Ïµ` will be discarded.
"""
function SVDD(kernel::KERNEL, xpos::Matrix{T}, xneg::Matrix{T}, C::Real, Ïµ::Real=1e-3) where {T <: Real, KERNEL <: XKernel}
    P = size(xpos,2); @assert P > 0 "no positives";
    N = size(xneg,2); @assert N > 0 "no negatives";

    if C < 1 / P
        BUG = """
        due to the constraints:
            âˆ‘â±¼yâ±¼Î±â±¼ = 1       (origin)
            âˆ‘â‚šÎ±â‚š - âˆ‘â‚™Î±â‚™ = 1  (inferred)
            0 â‰¤ Î±â±¼ â‰¤ C  â‡’  1 < âˆ‘â‚šÎ±â‚š â‰¤ C*P â‡’  C â‰¥ 1 / P
        where  p âˆˆ {j | yâ±¼ = +1, j = 1 ... N}, P = |p|
               n âˆˆ {j | yâ±¼ = -1, j = 1 ... N}
        the penalty coefficient C s.t. C â‰¥ 1 / P, but got $C â‰¥ 1 / $P .
        Now C would be set as 1 to make sure the code runs smoothly.
        """
        @warn BUG
        C = one(T)
    end

    y = svddlabel(P, N)
    x = hcat(xpos, xneg)
    return _SVDD(kernel, x, y, C, T(Ïµ))
end


"""
    SVDD(kernel <: XKernel, x::Matrix{Real}, y::Vector{Int}, C::Real, Ïµ::Real=1e-3)

`x` is the  data with label `y`,  `C` is the penalty coefficient (the bigger the less error allowed), 
lagrange multipliers below the threshold `Ïµ` will be discarded. Note that positive samples are labeled 
with +1, while the negative samples are labeled with -1. The function:

```julia
svddlabel(num_of_pos::Int, num_of_neg::Int)::Vector{Int}
```
could be a helper to create labels.
"""
function SVDD(kernel::KERNEL, x::Matrix{T}, y::Vector{Int}, C::Real, Ïµ::Real=1e-3) where {T <: Real, KERNEL <: XKernel}
    L = size(x, 2)  # number of features
    M = length(y)   # number of labels
    @assert L > 0 "no features";
    @assert M > 0 "no labels";
    @assert L == M "number of features ($L) â‰  number of labels($M)"

    P = 0
    for v âˆˆ y
        isone(v) && (P += 1)
    end
    N = L - P

    @assert P > 0 "no positives";
    @assert N > 0 "no negatives";

    C = T(C)
    if C < 1 / P
        BUG = """
        due to the constraints:
            âˆ‘â±¼yâ±¼Î±â±¼ = 1       (origin)
            âˆ‘â‚šÎ±â‚š - âˆ‘â‚™Î±â‚™ = 1  (inferred)
            0 â‰¤ Î±â±¼ â‰¤ C  â‡’  1 < âˆ‘â‚šÎ±â‚š â‰¤ C*P â‡’  C â‰¥ 1 / P
        where  p âˆˆ {j | yâ±¼ = +1, j = 1 ... N}, P = |p|
               n âˆˆ {j | yâ±¼ = -1, j = 1 ... N}
        the penalty coefficient C s.t. C â‰¥ 1 / P, but got $C â‰¥ 1 / $P .
        Now C would be set as 1 to make sure the code runs smoothly.
        """
        @warn BUG
        C = one(T)
    end

    return _SVDD(kernel, x, y, C, T(Ïµ))
end


# inference functor
function (Model::SVDD{T})(feat::Matrix{T}) where T
    Wáµ€KW = Model.Wáµ€KW
    xs   = Model.svecs
    RÂ²   = Model.RÂ²
    ğŸW   = Model.ğŸW
    Îº    = Model.kernel
    N  = size(feat, 2)
    Î”Â² = Vector{T}(undef, N)
    for i âˆˆ 1:N
        x = feat[:, i:i]
        Kxx = kmat(Îº, x,  x, obsdim=2)
        Kis = kmat(Îº, xs, x, obsdim=2)
        Î”Â²[i] = first(Kxx - ğŸW' * Kis .+ Wáµ€KW) - RÂ²
    end
    return Î”Â²
end


"""
    svddlabel(num_of_pos::Int, num_of_neg::Int) -> y::Vector{Int}

a helper to create labels. Note that positive samples are labeled with +1, 
while the negative samples are labeled with -1.
"""
function svddlabel(p::Int, n::Int)
    N = p + n
    label = Vector{Int}(undef, N)
    label[1   : p] .= +1
    label[p+1 : N] .= -1
    return label
end

